#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SMART PARSER - Parser thÃ´ng minh, tolerantes vá»›i thay Ä‘á»•i
CÃ³ thá»ƒ xá»­ lÃ½ nhiá»u format khÃ¡c nhau cá»§a file Word

Phase 1: Hybrid error model - Internal exceptions + Structured public API
Phase 1.3: Normalize input text for robustness
Phase 1.5: Safe JS rendering with json.dumps
Phase 2: O(N) algorithms for index + section tokenization
Phase 3: Architecture - Parser logic separated from Renderer
"""

import re
import unicodedata
import json
from typing import List, Dict, Any, Optional
from parser_models import (
    ParserError, IndexHeaderNotFound, NoSectionsFound,
    ParsedResult, ParsedIndex, Section,
    success_result, error_result_from_exception, error_result_manual
)

# Import renderer for JS generation (Phase 3: Separation of concerns)
from renderer import js_str, render_index, render_overview


# ============================================================================
# TASK 1.3: TEXT NORMALIZATION
# ============================================================================

def normalize_text(text: str) -> str:
    """
    Normalize text cho robust parsing

    Args:
        text: Raw input text

    Returns:
        Normalized text
    """
    # 1. Strip BOM if present
    if text.startswith('\ufeff'):
        text = text[1:]

    # 2. Unicode normalization (NFC - composed form)
    text = unicodedata.normalize('NFC', text)

    # 3. Normalize newlines
    text = text.replace('\r\n', '\n').replace('\r', '\n')

    # 4. Replace weird Unicode whitespace/newlines
    # U+2028 = LINE SEPARATOR, U+2029 = PARAGRAPH SEPARATOR
    text = text.replace('\u2028', '\n').replace('\u2029', '\n')

    # 5. (Optional) Replace other weird whitespace
    # U+00A0 = non-breaking space, U+2000-U+200A = various spaces
    # Keep them for now as they might be intentional in content

    return text


# ============================================================================
# TASK 2.1: UNION REGEX FOR INDEX BOUNDARY DETECTION (O(N))
# ============================================================================

# All index codes in the system
ALL_INDEX_CODES = [
    'VNINDEX', 'VN30', 'VN100', 'VNMIDCAP', 'VNREAL',
    'VNIT', 'VNHEAL', 'VNFIN', 'VNENE', 'VNCONS',
    'VNMAT', 'VNCOND', 'VNSML', 'VNFINSELECT', 'VNDIAMOND'
]

INDEX_NAMES = ALL_INDEX_CODES  # Legacy compatibility


# ============================================================================
# TASK 2.2: O(N) SECTION TOKENIZER (FIX #1)
# ============================================================================

# Section definitions: (regex_key, icon, title)
# FIX: Use stricter patterns with line anchors to avoid false matches
_SECTION_DEFINITIONS = [
    ('^XU\\s+HÆ¯á»šNG\\s+GIÃ$', 'ğŸ“ˆ', 'XU HÆ¯á»šNG GIÃ'),
    ('^XU\\s+HÆ¯á»šNG\\s+KHá»I\\s+LÆ¯á»¢NG$', 'ğŸ“Š', 'XU HÆ¯á»šNG KHá»I LÆ¯á»¢NG'),
    ('^Káº¾T\\s+Há»¢P\\s+XU\\s+HÆ¯á»šNG\\s+GIÃ\\s+VÃ€\\s+KHá»I\\s+LÆ¯á»¢NG$', 'ğŸ’¹', 'Káº¾T Há»¢P XU HÆ¯á»šNG GIÃ VÃ€ KHá»I LÆ¯á»¢NG'),
    ('^CUNG(?:\\s*\\-|\\s+\\-\\s+)Cáº¦U$', 'âš–ï¸', 'CUNG-Cáº¦U'),
    ('^Má»¨C\\s+GIÃ\\s+QUAN\\s+TRá»ŒNG$', 'ğŸ¯', 'Má»¨C GIÃ QUAN TRá»ŒNG'),
    ('^BIáº¾N\\s+Äá»˜NG\\s+GIÃ$', 'ğŸ“‰', 'BIáº¾N Äá»˜NG GIÃ'),
    ('^MÃ”\\s+HÃŒNH\\s+GIÃ(?:\\s+\\-|\\s+\\-\\s+)MÃ”\\s+HÃŒNH\\s+Náº¾N$', 'ğŸ•¯ï¸', 'MÃ” HÃŒNH GIÃ - MÃ” HÃŒNH Náº¾N'),
    ('^MARKET\\s+BREADTH(?:\\s+\\&|\\s+\\&\\s+)TÃ‚M\\s+LÃ\\s+THá»Š\\s+TRÆ¯á»œNG$', 'ğŸ‘¥', 'MARKET BREADTH & TÃ‚M LÃ THá»Š TRÆ¯á»œNG'),
    ('^Lá»ŠCH\\s+Sá»¬(?:\\s+\\&|\\s+\\&\\s+)XU\\s+HÆ¯á»šNG\\s+BREADTH$', 'ğŸ“œ', 'Lá»ŠCH Sá»¬ & XU HÆ¯á»šNG BREADTH'),
    ('^Rá»¦I\\s+RO$', 'âš ï¸', 'Rá»¦I RO'),
    ('^KHUYáº¾N\\s+NGHá»Š\\s+Vá»Š\\s+THáº¾$', 'ğŸ¯', 'KHUYáº¾N NGHá»Š Vá»Š THáº¾'),
    ('^GIÃ\\s+Má»¤C\\s+TIÃŠU$', 'ğŸ¯', 'GIÃ Má»¤C TIÃŠU'),
    ('^Ká»ŠCH\\s+Báº¢N\\s+WHAT(?:\\s+\\-|\\s+\\-\\s+)IF$|^WHAT\\s+IF$', 'ğŸ²', 'Ká»ŠCH Báº¢N WHAT-IF'),
    ('^THÃ”NG\\s+TIN\\s+CHUNG$', 'ğŸ“Š', 'THÃ”NG TIN CHUNG'),
    ('^Tá»”NG\\s+QUAN$', 'ğŸ“Š', 'THÃ”NG TIN CHUNG'),
]


def _build_section_union_pattern() -> re.Pattern:
    """
    Build union regex pattern for all section headers (O(N) tokenization)

    FIX: Added $ anchor to avoid false matches in sentences

    Returns compiled pattern with named groups for each section type
    """
    # Build pattern with named groups
    #
    # NOTE: DOCX->TXT can introduce numbering/bullets before section headers.
    # To avoid brittle parsing, we accept optional prefixes like:
    # - "1. ", "1) ", "A) ", "- ", "â€¢ "
    # and optional trailing ":".
    prefix = r'(?:\s*(?:\d+\.\s*|\d+\)\s*|[A-Z]\)\s*|[-â€¢]\s*))?'
    suffix = r'(?:\s*[:ï¼š])?'

    pattern_parts = []
    for i, (regex_key, _, _) in enumerate(_SECTION_DEFINITIONS):
        group_name = f'sec{i}'
        # Remove ^ and $ from pattern_key since we'll add them ourselves
        clean_pattern = regex_key.strip('^$')
        pattern_parts.append(rf'(?P<{group_name}>{prefix}{clean_pattern}{suffix})')

    # Join with | (OR) and wrap with anchors
    full_pattern = r'^\s*(' + '|'.join(pattern_parts) + r')\s*$'

    return re.compile(full_pattern, re.MULTILINE | re.IGNORECASE)


# Precompile section pattern once
_SECTION_UNION_PATTERN = _build_section_union_pattern()


def _get_section_info_by_match(match: re.Match) -> tuple:
    """
    Determine section info (icon, title) from match

    Args:
        match: Regex match object

    Returns:
        (icon, title) tuple
    """
    for i, (_, icon, title) in enumerate(_SECTION_DEFINITIONS):
        group_name = f'sec{i}'
        if match.group(group_name):
            return icon, title
    return None, None


def _parse_sections_from_content_optimized(index_content: str, index_code: str) -> List[Section]:
    """
    Parse sections tá»« index content - O(N) version

    Args:
        index_content: Ná»™i dung cá»§a index
        index_code: Code cá»§a index (cho debug)

    Returns:
        List of Section objects

    Raises:
        NoSectionsFound: Náº¿u khÃ´ng tÃ¬m tháº¥y section nÃ o
    """
    # Find all section headers in O(N) with union regex
    matches = list(_SECTION_UNION_PATTERN.finditer(index_content))

    if not matches:
        raise NoSectionsFound(index_code, f"No sections found in content")

    sections = []

    # Process each match
    for i, match in enumerate(matches):
        icon, title = _get_section_info_by_match(match)
        if not icon or not title:
            continue

        # Determine section boundaries
        section_start = match.end()

        # End = start of next section, or end of content
        if i + 1 < len(matches):
            section_end = matches[i + 1].start()
        else:
            section_end = len(index_content)

        # Extract section content
        section_content = index_content[section_start:section_end].strip()

        if not section_content:
            continue

        # Format thÃ nh HTML
        html_content = format_content_smart(section_content)

        # Special handling: TÃ¡ch "Ká»‹ch Báº£n What-if" náº¿u cÃ³ trong content
        split_marker = 'Ká»‹ch Báº£n "What-if"'
        if split_marker in html_content:
            # TÃ¡ch content táº¡i marker
            parts = html_content.split(split_marker, 1)

            # Section gá»‘c: Title cÅ© (pháº§n Ä‘áº§u)
            section = Section(
                icon=icon,
                title=f'`{title}`',
                content=parts[0].strip(),
                alert=('KHUYáº¾N NGHá»Š' in title)
            )
            sections.append(section)

            # Xá»­ lÃ½ pháº§n sau (cáº§n loáº¡i bá» PHáº¦N III náº¿u cÃ³)
            remaining_content = parts[1].strip()

            # Kiá»ƒm tra xem cÃ³ "PHáº¦N III" trong pháº§n sau khÃ´ng - Ä‘Ã¢y lÃ  marker káº¿t thÃºc, KHÃ”NG pháº£i section riÃªng
            phan3_match = re.search(r'PHáº¦N\s+III\s*:', remaining_content)
            if phan3_match:
                # Cáº¯t bá» PHáº¦N III vÃ  pháº§n sau nÃ³ (Ä‘Ã¢y lÃ  báº¯t Ä‘áº§u section tiáº¿p theo, khÃ´ng thuá»™c VNINDEX)
                whatif_content = remaining_content[:phan3_match.start()].strip()

                # Section Ká»‹ch Báº£n What-if (chá»‰ láº¥y pháº§n trÆ°á»›c PHáº¦N III)
                whatif_section = Section(
                    icon='ğŸŸ¡',
                    title='`Ká»‹ch Báº£n What-if`',
                    content=split_marker + whatif_content,
                    alert=False
                )
                sections.append(whatif_section)
            else:
                # KhÃ´ng cÃ³ PHáº¦N III, láº¥y toÃ n bá»™ pháº§n sau
                whatif_section = Section(
                    icon='ğŸŸ¡',
                    title='`Ká»‹ch Báº£n What-if`',
                    content=split_marker + remaining_content,
                    alert=False
                )
                sections.append(whatif_section)

            continue  # Skip normal processing

        # Normal processing
        section = Section(
            icon=icon,
            title=f'`{title}`',
            content=html_content,
            alert=('KHUYáº¾N NGHá»Š' in title)
        )
        sections.append(section)

    if not sections:
        raise NoSectionsFound(index_code, f"No valid sections found")

    return sections


# ============================================================================
# TASK 2.1 (CONTINUED): INDEX HEADER BOUNDARY DETECTION
# ============================================================================

def _build_union_header_pattern() -> re.Pattern:
    """
    Build union regex pattern for all index header variants

    Returns compiled pattern that matches all index headers in 1 pass

    Pattern matches:
    - PHáº¦N II: PHÃ‚N TÃCH CHá»ˆ Sá» VNINDEX
    - 1. Chá»‰ sá»‘ VN30 ...
    - PHÃ‚N TÃCH CHá»ˆ Sá» VN30
    - 1. VNREAL - Báº¥t Ä‘á»™ng sáº£n  (industry format - PHáº¢I cÃ³ dáº¥u -)
    - 1. VNREAL  (bare code - KHÃ”NG cÃ³ dáº¥u -)
    """
    # Escape all codes for regex
    CODE_ALT = "|".join(map(re.escape, ALL_INDEX_CODES))

    # Build union pattern vá»›i named groups
    # FIX: Äáº£o thá»© tá»± - industry_code PHáº¢I cÃ³ dáº¥u - hoáº·c :
    # bare_code KHÃ”NG Ä‘Æ°á»£c cÃ³ dáº¥u - hoáº·c :
    pattern = rf"""
        ^
        (?:
          PHáº¦N\s+[IVXLC]+\s*:\s*[^\n]*?\b(?P<part_code>{CODE_ALT})\b
          |\s*\d+\.\s*Chá»‰\s*sá»‘\s+(?P<chiso_code>{CODE_ALT})\b
          |\s*PHÃ‚N\s*TÃCH\s*CHá»ˆ\s*Sá»\s+(?P<phan_tich_code>{CODE_ALT})\b
          |\s*\d+\.\s*(?P<industry_code>{CODE_ALT})\b\s+(?:-|â€”|:)
          |\s*\d+\.\s*(?P<bare_code>{CODE_ALT})\b\s*(?![-|â€”|:])
        )
    """

    return re.compile(pattern, re.MULTILINE | re.IGNORECASE | re.VERBOSE)


# Precompile pattern once (module level)
_UNION_HEADER_PATTERN = _build_union_header_pattern()


def _find_all_index_boundaries_1pass(content: str) -> dict[str, tuple[int, int]]:
    """
    Find all index boundaries in 1 pass O(N)

    Args:
        content: Full document content

    Returns:
        dict mapping index_code -> (start_pos, end_pos)

    Raises:
        ParserError: If boundary detection fails
    """
    # Header type priority (higher = better)
    # FIX: Æ¯u tiÃªn format Ä‘áº§y Ä‘á»§ "CODE - NAME" (trong PHáº¦N IV)
    # hÆ¡n lÃ  bare CODE (trong PHáº¦N I overview)
    PRIORITY = {
        'part_code': 4,      # PHáº¦N II: ... VNINDEX (highest)
        'chiso_code': 3,     # 1. Chá»‰ sá»‘ VN30 ...
        'phan_tich_code': 3, # PHÃ‚N TÃCH CHá»ˆ Sá» VN30
        'industry_code': 2,  # 1. VNREAL - ... (PHáº¦N IV analysis)
        'bare_code': 1,      # 1. VNREAL (PHáº¦N I overview - lowest priority)
    }

    matches = []

    # Find all matches in 1 pass
    for match in _UNION_HEADER_PATTERN.finditer(content):
        # Determine which group matched
        code = None
        group_name = None
        for gn in ['part_code', 'chiso_code', 'phan_tich_code', 'industry_code', 'bare_code']:
            group_value = match.group(gn)
            if group_value:
                code = group_value.upper()  # Normalize to uppercase
                group_name = gn
                break

        if code and group_name:
            matches.append({
                'code': code,
                'start': match.start(),
                'end': match.end(),
                'line': match.group(0),
                'priority': PRIORITY[group_name]
            })

    # Sort by position
    matches.sort(key=lambda m: m['start'])

    # For each code, select the match with HIGHEST priority
    # (i.e., prefer "PHáº¦N II: VNINDEX" over "2. VNINDEX")
    best_matches = {}
    for match in matches:
        code = match['code']
        if code not in best_matches or match['priority'] > best_matches[code]['priority']:
            best_matches[code] = match

    # Calculate boundaries: end = start cá»§a match tiáº¿p theo, hoáº·c háº¿t file
    boundaries = {}
    sorted_codes = sorted(best_matches.keys(), key=lambda c: best_matches[c]['start'])

    for i, code in enumerate(sorted_codes):
        start = best_matches[code]['end']  # Content starts AFTER header
        if i + 1 < len(sorted_codes):
            next_code = sorted_codes[i + 1]
            end = best_matches[next_code]['start']  # Content ends BEFORE next header
        else:
            end = len(content)

        boundaries[code] = (start, end)

    return boundaries


# ============================================================================
# LEGACY HELPER FUNCTIONS (kept for backward compatibility during transition)
# ============================================================================

def _find_index_header(content, index_name):
    patterns = [
        rf'^\s*PHáº¦N\s+[IVXLC]+\s*:\s*.*\b{re.escape(index_name)}\b.*$',
        rf'^\s*\d+\.\s*Chá»‰\s*sá»‘\s+\b{re.escape(index_name)}\b.*$',
        rf'^\s*PHÃ‚N\s*TÃCH\s*CHá»ˆ\s*Sá»\s+\b{re.escape(index_name)}\b.*$',
        rf'^\s*\b{re.escape(index_name)}\b\s*$',
    ]

    best_match = None
    for pattern in patterns:
        match = re.search(pattern, content, re.IGNORECASE | re.MULTILINE)
        if match and (best_match is None or match.start() < best_match.start()):
            best_match = match

    return best_match

def _find_next_index_header_start(content, start_pos, current_index_name):
    index_alternation = "|".join(map(re.escape, INDEX_NAMES))
    next_header_pattern = (
        rf'^\s*PHáº¦N\s+[IVXLC]+\s*:\s*.*$'
        rf'|^\s*\d+\.\s*Chá»‰\s*sá»‘\s+(?:{index_alternation})\b.*$'
        rf'|^\s*PHÃ‚N\s*TÃCH\s*CHá»ˆ\s*Sá»\s+(?:{index_alternation})\b.*$'
    )

    best = None
    for match in re.finditer(next_header_pattern, content[start_pos:], re.IGNORECASE | re.MULTILINE):
        text = match.group(0)
        if re.search(rf'\b{re.escape(current_index_name)}\b', text, re.IGNORECASE):
            continue
        absolute = start_pos + match.start()
        if best is None or absolute < best:
            best = absolute

    return best


# ============================================================================
# TASK 1.2: NEW INTERNAL API (with structured error handling)
# ============================================================================


def _parse_index_internal(content: str, index_name: str, index_code: str) -> ParsedIndex:
    """
    Internal parser - raises exceptions on error

    Args:
        content: Full document content
        index_name: TÃªn index (vÃ­ dá»¥: "VN30")
        index_code: Code cho index (vÃ­ dá»¥: "vn30")

    Returns:
        ParsedIndex object

    Raises:
        IndexHeaderNotFound: Náº¿u khÃ´ng tÃ¬m tháº¥y header
        NoSectionsFound: Náº¿u khÃ´ng tÃ¬m tháº¥y sections
    """
    # TASK 2.1: Use 1-pass boundary detection
    boundaries = _find_all_index_boundaries_1pass(content)

    # Normalize index_code to uppercase for lookup (boundaries uses uppercase)
    code_upper = index_code.upper()

    # Check if requested index exists
    if code_upper not in boundaries:
        available = list(boundaries.keys())
        raise IndexHeaderNotFound(
            index_code=index_code,
            index_name=index_name,
            debug_context={"available_indices": available}
        )

    # Get boundaries for this index
    start_pos, end_pos = boundaries[code_upper]

    # Extract ná»™i dung index
    index_content = content[start_pos:end_pos]

    # Parse sections using O(N) tokenizer (TASK 2.2)
    sections = _parse_sections_from_content_optimized(index_content, index_code)

    # Return ParsedIndex
    return ParsedIndex(
        key=index_code,
        title=index_name,
        sections=sections
    )


def parse_index(content: str, index_name: str, index_code: str) -> ParsedResult:
    """
    Public API - Parse index vá»›i structured result

    Args:
        content: Full document content (string)
        index_name: TÃªn index (vÃ­ dá»¥: "VN30")
        index_code: Code cho index (vÃ­ dá»¥: "vn30")

    Returns:
        ParsedResult with status="success" or status="error"
    """
    try:
        # TASK 1.3: Normalize content before parsing
        normalized_content = normalize_text(content)
        parsed_index = _parse_index_internal(normalized_content, index_name, index_code)
        # Phase 3: Use renderer module for JS generation
        raw_js = render_index(parsed_index)
        return success_result(parsed_index, raw_js)
    except ParserError as e:
        return error_result_from_exception(e)


def _parse_overview_internal(content: str) -> ParsedIndex:
    """
    Internal overview parser - raises exceptions on error

    Args:
        content: Full document content

    Returns:
        ParsedIndex object

    Raises:
        NoSectionsFound: Náº¿u khÃ´ng tÃ¬m tháº¥y sections
    """
    # Overview náº±m trÆ°á»›c pháº§n phÃ¢n tÃ­ch VNINDEX (trÃ¡nh match tÃªn index trong pháº§n "coverage" á»Ÿ Ä‘áº§u)
    first_index_match = re.search(r'^\s*PHáº¦N\s+II\b.*$', content, re.IGNORECASE | re.MULTILINE)
    overview_content = content[:first_index_match.start()] if first_index_match else content

    overview_sections = [
        ('ğŸ“Š', 'Tá»”NG QUAN THá»Š TRÆ¯á»œNG', r'^\s*\d+\.\s*Tá»”NG\s*QUAN\s*THá»Š\s*TRÆ¯á»œNG\b.*$'),
        ('ğŸ”—', 'PHÃ‚N TÃCH Má»I QUAN Há»†', r'^\s*\d+\.\s*PHÃ‚N\s*TÃCH\s*Má»I\s*QUAN\s*Há»†\b.*$'),
        ('ğŸ’°', 'DÃ’NG TIá»€N & XU HÆ¯á»šNG', r'^\s*\d+\.\s*DÃ’NG\s*TIá»€N\s*&\s*XU\s*HÆ¯á»šNG\b.*$'),
        ('ğŸ§©', 'Há»˜I Tá»¤ Ká»¸ THUáº¬T', r'^\s*\d+\.\s*Há»˜I\s*Tá»¤\s*Ká»¸\s*THUáº¬T\b.*$'),
        ('ğŸ†', 'Xáº¾P Háº NG', r'^\s*\d+\.\s*Xáº¾P\s*Háº NG\b.*$'),
        ('ğŸ­', 'PHÃ‚N TÃCH NGÃ€NH', r'^\s*\d+\.\s*PHÃ‚N\s*TÃCH\s*NGÃ€NH\b.*$'),
        ('ğŸ“', 'NHáº¬N Äá»ŠNH', r'^\s*\d+\.\s*NHáº¬N\s*Äá»ŠNH\b.*$'),
    ]

    sections = []
    for icon, title, pattern in overview_sections:
        match = re.search(pattern, overview_content, re.IGNORECASE | re.MULTILINE)
        if not match:
            continue

        start = match.end()

        # Find nearest next section header occurrence
        end = len(overview_content)
        for _, __, next_pattern in overview_sections:
            next_match = re.search(next_pattern, overview_content[start:], re.IGNORECASE | re.MULTILINE)
            if next_match:
                end = min(end, start + next_match.start())

        section_content = overview_content[start:end].strip()
        if not section_content:
            continue

        section = Section(
            icon=icon,
            title=f'`{title}`',
            content=format_content_smart(section_content)
        )
        sections.append(section)

    if not sections:
        raise NoSectionsFound("overview", "overview", debug_context={"content_length": len(overview_content)})

    return ParsedIndex(
        key="overview",
        title="Tá»”NG QUAN THá»Š TRÆ¯á»œNG",
        sections=sections
    )


def parse_overview(content: str) -> ParsedResult:
    """
    Public API - Parse overview vá»›i structured result

    Args:
        content: Full document content (string)

    Returns:
        ParsedResult with status="success" or status="error"
    """
    try:
        # TASK 1.3: Normalize content before parsing
        normalized_content = normalize_text(content)
        parsed_index = _parse_overview_internal(normalized_content)
        # Phase 3: Use renderer module for JS generation
        raw_js = render_overview(parsed_index)
        return success_result(parsed_index, raw_js)
    except ParserError as e:
        return error_result_from_exception(e)


# ============================================================================
# OLD API (Backward compatibility - will be deprecated)
# ============================================================================

def parse_index_from_content(content, index_name, index_code):
    """
    Parser thÃ´ng minh tá»« content string - tá»± Ä‘á»™ng detect sections

    Args:
        content: Ná»™i dung file text (string)
        index_name: TÃªn index (vÃ­ dá»¥: "VN30")
        index_code: Code cho index (vÃ­ dá»¥: "vn30")

    Returns:
        JavaScript object string
    """
    # Content Ä‘Ã£ Ä‘Æ°á»£c Ä‘á»c tá»« ngoÃ i, khÃ´ng cáº§n open file ná»¯a

    # 1. Tá»° Äá»˜NG TÃŒM Vá»Š TRÃ INDEX (khÃ´ng hardcode line numbers)
    index_match = _find_index_header(content, index_name)

    if not index_match:
        return f"# Lá»–I: KhÃ´ng tÃ¬m tháº¥y {index_name} trong file\n"

    # 2. TÃ¬m vá»‹ trÃ­ báº¯t Ä‘áº§u (sau header index)
    start_pos = index_match.end()

    # 3. TÃ¬m vá»‹ trÃ­ káº¿t thÃºc (Ä‘áº§u index tiáº¿p theo hoáº·c háº¿t file)
    next_start = _find_next_index_header_start(content, start_pos, index_name)
    end_pos = next_start if next_start is not None else len(content)

    # 4. Extract ná»™i dung index
    index_content = content[start_pos:end_pos]

    # 5. Tá»° Äá»˜NG DETECT SECTIONS (flexible patterns)
    sections = []

    # Pattern FLEXIBLE - tolerates vá»›i spacing, format
    section_patterns = [
        (r'XU.*HÆ¯á»šNG.*GIÃ', 'ğŸ“ˆ', 'XU HÆ¯á»šNG GIÃ'),
        (r'XU.*HÆ¯á»šNG.*KHá»I.*LÆ¯á»¢NG', 'ğŸ“Š', 'XU HÆ¯á»šNG KHá»I LÆ¯á»¢NG'),
        (r'Káº¾T.*Há»¢P.*XU.*HÆ¯á»šNG', 'ğŸ’¹', 'Káº¾T Há»¢P XU HÆ¯á»šNG GIÃ VÃ€ KHá»I LÆ¯á»¢NG'),
        (r'CUNG.*Cáº¦U|CUNG.*Cáº¦U', 'âš–ï¸', 'CUNG-Cáº¦U'),
        (r'Má»¨C.*GIÃ.*QUAN.*TRá»ŒNG', 'ğŸ¯', 'Má»¨C GIÃ QUAN TRá»ŒNG'),
        (r'BIáº¾N.*Äá»˜NG.*GIÃ', 'ğŸ“‰', 'BIáº¾N Äá»˜NG GIÃ'),
        (r'MÃ”.*HÃŒNH.*GIÃ.*MÃ”.*HÃŒNH.*Náº¾N', 'ğŸ•¯ï¸', 'MÃ” HÃŒNH GIÃ - MÃ” HÃŒNH Náº¾N'),
        (r'MARKET.*BREADTH|TÃ‚M.*LÃ.*THá»Š.*TRÆ¯á»œNG', 'ğŸ‘¥', 'MARKET BREADTH & TÃ‚M LÃ THá»Š TRÆ¯á»œNG'),
        (r'Lá»ŠCH.*Sá»¬.*XU.*HÆ¯á»šNG.*BREADTH', 'ğŸ“œ', 'Lá»ŠCH Sá»¬ & XU HÆ¯á»šNG BREADTH'),
        (r'Rá»¦I.*RO', 'âš ï¸', 'Rá»¦I RO'),
        (r'KHUYáº¾N.*NGHá»Š.*Vá»Š.*THáº¾', 'ğŸ¯', 'KHUYáº¾N NGHá»Š Vá»Š THáº¾'),
        (r'GIÃ.*Má»¤C.*TIÃŠU', 'ğŸ¯', 'GIÃ Má»¤C TIÃŠU'),
        (r'Ká»ŠCH.*Báº¢N.*WHAT.*IF|WHAT.*IF', 'ğŸ²', 'Ká»ŠCH Báº¢N WHAT-IF'),
        (r'THÃ”NG.*TIN.*CHUNG', 'ğŸ“Š', 'THÃ”NG TIN CHUNG'),
        (r'Tá»”NG.*QUAN', 'ğŸ“Š', 'THÃ”NG TIN CHUNG'),
    ]

    # TÃ¬m táº¥t cáº£ sections
    for pattern, icon, title in section_patterns:
        match = re.search(pattern, index_content, re.IGNORECASE)
        if match:
            # Extract content tá»« Ä‘Ã¢y Ä‘áº¿n section tiáº¿p theo
            section_start = match.end()

            # TÃ¬m section tiáº¿p theo
            next_section_pos = len(index_content)
            for next_pattern, _, _ in section_patterns:
                next_match = re.search(next_pattern, index_content[section_start:], re.IGNORECASE)
                if next_match and next_match.start() < next_section_pos:
                    next_section_pos = next_match.start()

            # Extract content
            section_content = index_content[section_start:section_start + next_section_pos].strip()

            # Format thÃ nh HTML
            if section_content:
                html_content = format_content_smart(section_content)

                section_obj = {
                    'icon': icon,
                    'title': f'`{title}`',
                    'content': html_content
                }

                # Add alert flag cho KHUYáº¾N NGHá»Š
                if 'KHUYáº¾N NGHá»Š' in title:
                    section_obj['alert'] = True

                sections.append(section_obj)

    # 6. Generate JavaScript object
    return generate_js_object_smart(index_code, index_name, sections)


def parse_smart(filepath, index_name, index_code):
    """
    Parser thÃ´ng minh - backward compatibility wrapper

    Args:
        filepath: ÄÆ°á»ng dáº«n file text
        index_name: TÃªn index (vÃ­ dá»¥: "VN30")
        index_code: Code cho index (vÃ­ dá»¥: "vn30")

    Returns:
        JavaScript object string
    """
    with open(filepath, 'r', encoding='utf-8') as f:
        content = f.read()
    return parse_index_from_content(content, index_name, index_code)

def parse_overview_from_content(content):
    """
    Parse pháº§n Tá»”NG QUAN/OVERVIEW tá»« content string.

    Args:
        content: Ná»™i dung file text (string)

    Returns:
        JavaScript object string (overview: {...})
    """
    # Content Ä‘Ã£ Ä‘Æ°á»£c Ä‘á»c tá»« ngoÃ i, khÃ´ng cáº§n open file ná»¯a

    # Overview náº±m trÆ°á»›c pháº§n phÃ¢n tÃ­ch VNINDEX (trÃ¡nh match tÃªn index trong pháº§n "coverage" á»Ÿ Ä‘áº§u)
    first_index_match = re.search(r'^\s*PHáº¦N\s+II\b.*$', content, re.IGNORECASE | re.MULTILINE)
    overview_content = content[:first_index_match.start()] if first_index_match else content

    overview_sections = [
        ('ğŸ“Š', 'Tá»”NG QUAN THá»Š TRÆ¯á»œNG', r'^\s*\d+\.\s*Tá»”NG\s*QUAN\s*THá»Š\s*TRÆ¯á»œNG\b.*$'),
        ('ğŸ”—', 'PHÃ‚N TÃCH Má»I QUAN Há»†', r'^\s*\d+\.\s*PHÃ‚N\s*TÃCH\s*Má»I\s*QUAN\s*Há»†\b.*$'),
        ('ğŸ’°', 'DÃ’NG TIá»€N & XU HÆ¯á»šNG', r'^\s*\d+\.\s*DÃ’NG\s*TIá»€N\s*&\s*XU\s*HÆ¯á»šNG\b.*$'),
        ('ğŸ§©', 'Há»˜I Tá»¤ Ká»¸ THUáº¬T', r'^\s*\d+\.\s*Há»˜I\s*Tá»¤\s*Ká»¸\s*THUáº¬T\b.*$'),
        ('ğŸ†', 'Xáº¾P Háº NG', r'^\s*\d+\.\s*Xáº¾P\s*Háº NG\b.*$'),
        ('ğŸ­', 'PHÃ‚N TÃCH NGÃ€NH', r'^\s*\d+\.\s*PHÃ‚N\s*TÃCH\s*NGÃ€NH\b.*$'),
        ('ğŸ“', 'NHáº¬N Äá»ŠNH', r'^\s*\d+\.\s*NHáº¬N\s*Äá»ŠNH\b.*$'),
    ]

    sections = []
    for icon, title, pattern in overview_sections:
        match = re.search(pattern, overview_content, re.IGNORECASE | re.MULTILINE)
        if not match:
            continue

        start = match.end()

        # Find nearest next section header occurrence
        end = len(overview_content)
        for _, __, next_pattern in overview_sections:
            next_match = re.search(next_pattern, overview_content[start:], re.IGNORECASE | re.MULTILINE)
            if next_match:
                end = min(end, start + next_match.start())

        section_content = overview_content[start:end].strip()
        if not section_content:
            continue

        sections.append({
            'icon': icon,
            'title': f'`{title}`',
            'content': format_content_smart(section_content),
        })

    if not sections:
        return "# Lá»–I: KhÃ´ng tÃ¬m tháº¥y section nÃ o cho OVERVIEW\n"

    # Custom title Ä‘á»ƒ giá»‘ng full_data.js hiá»‡n táº¡i
    sections_js = []
    for s in sections:
        sections_js.append(f"""            {{
                icon: "{s['icon'].replace('`', '')}",
                title: {s['title']},
                content: {s['content']}
            }},""")

    return f"""    overview: {{
        title: `ğŸ“Š BÃO CÃO Tá»”NG Há»¢P THá»Š TRÆ¯á»œNG`,
        sections: [
{chr(10).join(sections_js)[:-1]}
        ]
    }}"""


def parse_overview_smart(filepath):
    """
    Parse pháº§n Tá»”NG QUAN/OVERVIEW á»Ÿ Ä‘áº§u bÃ¡o cÃ¡o - backward compatibility wrapper.

    Args:
        filepath: ÄÆ°á»ng dáº«n file text

    Returns:
        JavaScript object string (overview: {...})
    """
    with open(filepath, 'r', encoding='utf-8') as f:
        content = f.read()
    return parse_overview_from_content(content)


def format_content_smart(content):
    """
    Format content thÃ nh HTML vá»›i smart parsing
    Tolerates vá»›i nhiá»u format khÃ¡c nhau

    TASK 1.4: Generate valid HTML structure
    FIX #2: Return plain HTML (no backticks) for JS safety
    """
    lines = content.split('\n')
    html_parts = []
    in_bullet_list = False

    for line in lines:
        line = line.strip()
        if not line:
            if in_bullet_list:
                html_parts.append('</ul>')
                in_bullet_list = False
            continue

        # Detect bullet points
        if re.match(r'^[\s]*(â€¢|[-*])\s+', line):
            if not in_bullet_list:
                html_parts.append('<ul>')
                in_bullet_list = True
            # Remove bullet marker, wrap in <li>
            clean_line = re.sub(r'^[\s]*(â€¢|[-*])\s+', '', line)
            html_parts.append(f'<li>{clean_line}</li>')
        else:
            if in_bullet_list:
                html_parts.append('</ul>')
                in_bullet_list = False
            # Bold text: **text** or __text__
            line = re.sub(r'\*\*(.*?)\*\*', r'<strong>\1</strong>', line)
            line = re.sub(r'__(.*?)__', r'<strong>\1</strong>', line)
            html_parts.append(f'<p>{line}</p>')

    if in_bullet_list:
        html_parts.append('</ul>')

    html_content = '\n                '.join(html_parts)
    # FIX #2: Return plain HTML, NOT template literal
    return f"<div class='info-box'>{html_content}</div>"


def generate_js_object_smart(index_code, index_name, sections):
    """Generate JavaScript object vá»›i consistent format"""

    if not sections:
        return f"    # Lá»–I: KhÃ´ng tÃ¬m tháº¥y sections nÃ o cho {index_name}\n"

    sections_js = []
    for s in sections:
        section_str = f"""            {{
                icon: "{s['icon'].replace('`', '')}",
                title: {s['title']},
                content: {s['content']}"""

        if s.get('alert'):
            section_str += ',\n                alert: true'

        section_str += '\n            },'
        sections_js.append(section_str)

    js_object = f'''    {index_code}: {{
        title: `{index_name} - PHÃ‚N TÃCH Äáº¦Y Äá»¦ 100%`,
        sections: [
{chr(10).join(sections_js)[:-1]}
        ]
    }}'''

    return js_object


# Example usage
if __name__ == '__main__':
    import sys

    filepath = sys.argv[1] if len(sys.argv) > 1 else 'baocao_full.txt'

    # Tá»± Ä‘á»™ng parse VN30 - khÃ´ng cáº§n hardcode line numbers!
    vn30_js = parse_smart(filepath, 'VN30', 'vn30')

    print("âœ… Smart Parser Output:")
    print(vn30_js[:500] + "...")
